{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification for Stack overflow questions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9UlPMglXH2lzuZaTiuNke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedAnasAli3/Masters-course-ML-projects/blob/main/Text_Classification_for_Stack_overflow_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z2Un4pGetdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f25636-c27d-4f0f-aed0-5e44136c4ad6"
      },
      "source": [
        "# You need TF 1.13.1 to deploy this on AI Platform \n",
        "!pip install tensorflow==1.13.1\n",
        "\n",
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.39.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.6.4)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F9JWI_FEHtM"
      },
      "source": [
        "# Authenticate to your cloud account\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck1oNJiGEdzf",
        "outputId": "1921f529-de47-4ccb-8365-dca60724efaf"
      },
      "source": [
        "\n",
        "# Download the Stack Overflow data (or replace with your own text data)\n",
        "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
            "/ [1 files][276.7 MiB/276.7 MiB]                                                \n",
            "Operation completed over 1 objects/276.7 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kLrrskfREnfa",
        "outputId": "6452cde6-69b0-4ee5-ef17-704662f0f570"
      },
      "source": [
        "\n",
        "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv', names=['tags', 'original_tags', 'text'], header=0)\n",
        "data = data.drop(columns=['original_tags'])\n",
        "data = data.dropna()\n",
        "\n",
        "data = shuffle(data, random_state=22)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>182914</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>avocado image captioning model not compiling b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48361</th>\n",
              "      <td>pandas</td>\n",
              "      <td>return excel file from avocado with flask in f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181447</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>validating with generator (avocado) i'm trying...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66307</th>\n",
              "      <td>pandas</td>\n",
              "      <td>avocado multiindex dataframe selecting data gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11283</th>\n",
              "      <td>pandas</td>\n",
              "      <td>get rightmost non-zero value position for each...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    tags                                               text\n",
              "182914  tensorflow,keras  avocado image captioning model not compiling b...\n",
              "48361             pandas  return excel file from avocado with flask in f...\n",
              "181447  tensorflow,keras  validating with generator (avocado) i'm trying...\n",
              "66307             pandas  avocado multiindex dataframe selecting data gi...\n",
              "11283             pandas  get rightmost non-zero value position for each..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTkFQpCuEwJh",
        "outputId": "544518ee-3d93-4a9c-951f-df438d770dfb"
      },
      "source": [
        "# Encode top tags to multi-hot\n",
        "tags_split = [tags.split(',') for tags in data['tags'].values]\n",
        "print(type(tags_split))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcWUsXxAE0mb",
        "outputId": "a0528fd5-af4f-476c-cc8b-544c61dc1cac"
      },
      "source": [
        "#\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
        "num_tags = len(tags_encoded[0])\n",
        "print(data['text'].values[0])\n",
        "print(tag_encoder.classes_)\n",
        "print(tags_encoded[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avocado image captioning model not compiling because of concatenate layer when mask_zero=true in a previous layer i am new to avocado and i am trying to implement a model for an image captioning project.   i am trying to reproduce the model from image captioning pre-inject architecture (the picture is taken from this paper: where to put the image in an image captioning generator) (but with a minor difference: generating a word at each time step instead of only generating a single word at the end), in which the inputs for the lstm at the first time step are the embedded cnn features. the lstm should support variable input length and in order to do this i padded all the sequences with zeros so that all of them have maxlen time steps.  the code for the model i have right now is the following:    def get_model(model_name, batch_size, maxlen, voc_size, embed_size,          cnn_feats_size, dropout_rate):      # create input layer for the cnn features     cnn_feats_input = input(shape=(cnn_feats_size,))      # normalize cnn features      normalized_cnn_feats = batchnormalization(axis=-1)(cnn_feats_input)      # embed cnn features to have same dimension with word embeddings     embedded_cnn_feats = dense(embed_size)(normalized_cnn_feats)      # add time dimension so that this layer output shape is (none, 1, embed_size)     final_cnn_feats = repeatvector(1)(embedded_cnn_feats)      # create input layer for the captions (each caption has max maxlen words)     caption_input = input(shape=(maxlen,))      # embed the captions     embedded_caption = embedding(input_dim=voc_size,                                  output_dim=embed_size,                                  input_length=maxlen)(caption_input)      # concatenate cnn features and the captions.     # ouput shape should be (none, maxlen + 1, embed_size)     img_caption_concat = concatenate([final_cnn_feats, embedded_caption], axis=1)      # now feed the concatenation into a lstm layer (many-to-many)     lstm_layer = lstm(units=embed_size,                       input_shape=(maxlen + 1, embed_size),   # one additional time step for the image features                       return_sequences=true,                       dropout=dropout_rate)(img_caption_concat)      # create a fully connected layer to make the predictions     pred_layer = timedistributed(dense(units=voc_size))(lstm_layer)      # build the model with cnn features and captions as input and      # predictions output     model = model(inputs=[cnn_feats_input, caption_input],                    outputs=pred_layer)      optimizer = adam(lr=0.0001,                       beta_1=0.9,                       beta_2=0.999,                       epsilon=1e-8)      model.compile(loss='categorical_crossentropy',optimizer=optimizer)     model.summary()      return model   the model (as it is above) compiles without any errors (see: model summary) and i managed to train it using my data. however, it doesn't take into account the fact that my sequences are zero-padded and the results won't be accurate because of this. when i try to change the embedding layer in order to support masking (also making sure that i use voc_size + 1 instead of voc_size, as it's mentioned in the documentation) like this:  embedded_caption = embedding(input_dim=voc_size + 1,                              output_dim=embed_size,                              input_length=maxlen, mask_zero=true)(caption_input)   i get the following error:  traceback (most recent call last):   file \"/export/home/.../py3_env/lib/python3.5/site-packages/avocado/python/framework/ops.py\", line 1567, in _create_c_op     c_op = c_api.avocado_finishoperation(op_desc) avocado.python.framework.errors_impl.invalidargumenterror: dimension 0 in both shapes must be equal, but are 200 and 1. shapes are [200] and [1]. for 'concatenate_1/concat_1' (op: 'concatv2') with input shapes: [?,1,200], [?,25,1], [] and with computed input tensors: input[2] = &lt;1&gt;   i don't know why it says the shape of the second array is [?, 25, 1], as i am printing its shape before the concatenation and it's [?, 25, 200] (as it should be).  i don't understand why there'd be an issue with a model that compiles and works fine without that parameter, but i assume there's something i am missing.  i have also been thinking about using a masking layer instead of mask_zero=true, but it should be before the embedding and the documentation says that the embedding layer should be the first layer in a model (after the input).   is there anything i could change in order to fix this or is there a workaround to this ?\n",
            "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow']\n",
            "[1 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5b3odKqGI60",
        "outputId": "ae0f6382-b257-4e58-c364-2710c16754e5"
      },
      "source": [
        "\n",
        "# Split our data into train and test sets\n",
        "train_size = int(len(data) * .8)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 150559\n",
            "Test size: 37640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBpuF3Ukyzn"
      },
      "source": [
        "# Split our labels into train and test sets\n",
        "train_tags = tags_encoded[:train_size]\n",
        "test_tags = tags_encoded[train_size:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM1YJmYSk1Pd",
        "outputId": "eb4a8600-d4b4-4fd5-8ca6-0d9baef9d4ef"
      },
      "source": [
        "\n",
        "# Pre-processing data: create our tokenizer class\n",
        "%%writefile preprocess.py\n",
        "\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "class TextPreprocessor(object):\n",
        "  def __init__(self, vocab_size):\n",
        "    self._vocab_size = vocab_size\n",
        "    self._tokenizer = None\n",
        "  \n",
        "  def create_tokenizer(self, text_list):\n",
        "    tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
        "    tokenizer.fit_on_texts(text_list)\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "  def transform_text(self, text_list):\n",
        "    text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
        "    return text_matrix"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing preprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L2eGRs0k46g"
      },
      "source": [
        "# Creating a vocabulary from training corpus(collection of texts). This will take time as it uses the bag size of 400 for all sentences.\n",
        "from preprocess import TextPreprocessor\n",
        "\n",
        "VOCAB_SIZE=400 # This is a hyperparameter, try out different values for your dataset\n",
        "\n",
        "train_qs = data['text'].values[:train_size]\n",
        "test_qs = data['text'].values[train_size:]\n",
        "\n",
        "processor = TextPreprocessor(VOCAB_SIZE)\n",
        "processor.create_tokenizer(train_qs)\n",
        "\n",
        "body_train = processor.transform_text(train_qs)\n",
        "body_test = processor.transform_text(test_qs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4v7sys6lZSN",
        "outputId": "f123a2fc-696c-49c7-a751-1afda80ba147"
      },
      "source": [
        "# Preview the first input from our training data\n",
        "print(len(body_train[0]))\n",
        "print(body_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VWyb-rclwNe"
      },
      "source": [
        "\n",
        "# Save the processor state of the tokenizer using python's pickle module and saving it as serialised object.\n",
        "import pickle\n",
        "\n",
        "with open('./processor_state.pkl', 'wb') as f:\n",
        "  pickle.dump(processor, f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK_g9ERNm862"
      },
      "source": [
        "def create_model(vocab_size, num_tags):\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8b_b0jjm91f",
        "outputId": "54dac08d-cdb4-4ffe-a8ed-7de9f44c58f9"
      },
      "source": [
        "model = create_model(VOCAB_SIZE, num_tags)\n",
        "model.summary()\n",
        "\n",
        "# Train and evaluate the model\n",
        "model.fit(body_train, train_tags, epochs=3, batch_size=128, validation_split=0.1)\n",
        "print('Eval loss/accuracy:{}'.format(\n",
        "  model.evaluate(body_test, test_tags, batch_size=128)))\n",
        "\n",
        "# Export the model to a file\n",
        "model.save('keras_saved_model.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                20050     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 130       \n",
            "=================================================================\n",
            "Total params: 21,455\n",
            "Trainable params: 21,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 135503 samples, validate on 15056 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3\n",
            "135503/135503 [==============================] - 5s 38us/sample - loss: 0.1474 - acc: 0.9433 - val_loss: 0.1086 - val_acc: 0.9584\n",
            "Epoch 2/3\n",
            "135503/135503 [==============================] - 5s 35us/sample - loss: 0.1048 - acc: 0.9593 - val_loss: 0.1019 - val_acc: 0.9600\n",
            "Epoch 3/3\n",
            "135503/135503 [==============================] - 5s 35us/sample - loss: 0.1000 - acc: 0.9606 - val_loss: 0.0993 - val_acc: 0.9613\n",
            "37640/37640 [==============================] - 1s 15us/sample - loss: 0.1025 - acc: 0.9601\n",
            "Eval loss/accuracy:[0.10250110057094525, 0.96011704]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g55hO3U-nAX0",
        "outputId": "9d627218-4688-4b9b-bb18-08b01eddd560"
      },
      "source": [
        "# Use custom model prediction to save our model + tokenizer\n",
        "%%writefile model_prediction.py\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class CustomModelPrediction(object):\n",
        "\n",
        "  def __init__(self, model, processor):\n",
        "    self._model = model\n",
        "    self._processor = processor\n",
        "  \n",
        "  def predict(self, instances, **kwargs):\n",
        "    preprocessed_data = self._processor.transform_text(instances)\n",
        "    predictions = self._model.predict(preprocessed_data)\n",
        "    return predictions.tolist()\n",
        "\n",
        "  @classmethod\n",
        "  def from_path(cls, model_dir):\n",
        "    import tensorflow.keras as keras\n",
        "    model = keras.models.load_model(\n",
        "      os.path.join(model_dir,'keras_saved_model.h5'))\n",
        "    with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
        "      processor = pickle.load(f)\n",
        "\n",
        "    return cls(model, processor)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model_prediction.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4MxbViAnJTN"
      },
      "source": [
        "#sample test question text\n",
        "test_requests = [\n",
        "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
        "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "wd2hLnSRnWvO",
        "outputId": "6bb1f09f-6bfd-4bd7-8278-dfde8fd12dbb"
      },
      "source": [
        "from model_prediction import CustomModelPrediction\n",
        "\n",
        "# classifier = CustomModelPrediction.from_path('.')\n",
        "results = CustomModelPrediction.from_path('.').predict(test_requests)\n",
        "print(results)\n",
        "\n",
        "for i in range(len(results)):\n",
        "  print('Predicted labels:')\n",
        "  for idx,val in enumerate(results[i]):\n",
        "    if val > 0.7:\n",
        "      print(tag_encoder.classes_[idx])\n",
        "  print('\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a3c9c84ad474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# classifier = CustomModelPrediction.from_path('.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomModelPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_requests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model_prediction.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, model_dir)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     model = keras.models.load_model(\n\u001b[0;32m---> 20\u001b[0;31m       os.path.join(model_dir,'keras_saved_model.h5'))\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'processor_state.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVQx0sBqvi3n",
        "outputId": "d55ef30a-b9fb-4866-99d6-866e80e63bc3"
      },
      "source": [
        "\n",
        "!pip install shap\n",
        "!pip install colored"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 356 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491648 sha256=d2eba1bb291e2cd2b3682661b4b31308a48955e2d52c8864c99ca9a7e0e28631\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.39.0 slicer-0.0.7\n",
            "Collecting colored\n",
            "  Downloading colored-1.4.2.tar.gz (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: colored\n",
            "  Building wheel for colored (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colored: filename=colored-1.4.2-py3-none-any.whl size=14023 sha256=bc7092f6564b28decb312693a1186a9b9ddf1a8bd86f9ad4b5425b39abd4131a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/e1/fb/d0e85a8383ff58962319bb81c46e398fa1f4bb9e1feb0f81c4\n",
            "Successfully built colored\n",
            "Installing collected packages: colored\n",
            "Successfully installed colored-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Ihv0sivtfv"
      },
      "source": [
        "\n",
        "import shap\n",
        "attrib_data = body_train[:200]\n",
        "explainer = shap.DeepExplainer(model, attrib_data)\n",
        "\n",
        "num_explanations = 25\n",
        "shap_vals = explainer.shap_values(body_test[:num_explanations])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyfOMFPVvyPX"
      },
      "source": [
        "words = processor._tokenizer.word_index"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4BmIqf0v1J3",
        "outputId": "043d58cc-a58f-4569-d51a-050d39bb3894"
      },
      "source": [
        "word_lookup = list()\n",
        "for i in words.keys():\n",
        "  word_lookup.append(i)\n",
        "\n",
        "word_lookup = [''] + word_lookup\n",
        "print(word_lookup[:100])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '0', 'the', 'avocado', 'i', '1', 'to', 'a', 'in', '2', 'and', 'is', 'of', 'for', '3', 'x', 'data', 'this', 'with', 'df', 'as', '5', 'it', 'import', '4', 'from', 'gt', 'y', 'that', 'have', 'model', 'dataframe', 'file', 'self', 'but', '00', \"'\", 'my', 'on', 'np', '10', 'train', 'how', 'python', 'if', 'not', 'get', '7', 'line', '6', '01', 'be', 'like', 'lt', 'using', 'c', 'nan', 'am', 'column', 'py', 'name', 'code', 'input', 'index', 'values', 'can', 'size', 'do', 'plot', 'print', 'columns', 'b', 'so', 'value', 'lib', 'shape', 'set', '8', 'test', 'want', 'error', 'are', 'output', 'an', 'true', 'packages', '12', 'use', 'time', 'n', 'batch', 'return', 'or', 'add', 'by', 'def', 'would', 'list', 'when', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "mwiaUb6dv3Ym",
        "outputId": "5789aa5e-6d2d-461d-c4e3-8045488f76c0"
      },
      "source": [
        "shap.summary_plot(shap_vals, feature_names=word_lookup, class_names=tag_encoder.classes_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x684 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nETdF1Wpv5n1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}